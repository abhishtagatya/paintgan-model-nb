{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Google Colab Template",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNeavjmFiZ0ylFpvGlvjxOF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishtagatya/paintgan-model-comparison/blob/main/google_colab_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Name\n",
        "\n",
        "Model Description\n",
        "\n",
        "Paper\n",
        "\n",
        "### Dataset\n",
        "\n",
        "```\n",
        "PaintGAN 80K\n",
        "Just a sliced dataset of Places365 and WikiArt each containing roughly 80,000 content and style images each.\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y2Mq2uxrmcXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prelimenary Setup\n",
        "\n",
        "Setting up and loading dataset from PaintGAN 80K using Tensorflow DataLoader"
      ],
      "metadata": {
        "id": "pJdosIWUnV7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sPEr5kU1mbn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huREvrl2lavV"
      },
      "outputs": [],
      "source": [
        "!unzip drive/MyDrive/Dataset/paintgan-80k.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import imageio\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "#@title ## Model Training Parameters { display-mode: \"both\" }\n",
        "#@markdown Change training parameters based on experimentation\n",
        "\n",
        "# Defining Training Parameters\n",
        "MODEL_NAME = \"\" #@param{type:\"string\"}\n",
        "IMAGE_SIZE = (256, 256) #@param{type:\"raw\"}\n",
        "BATCH_SIZE = 8 #@param{type:\"integer\"}\n",
        "EPOCHS = 30 #@param{type:\"integer\"}\n",
        "CHECKPOINT_PER_EPOCH = 5 #@param{type:\"integer\"}\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "WIKIART_BASEPATH = \"paintgan-dataset/wikiart\"\n",
        "P365_BASEPATH = \"paintgan-dataset/places365\"\n",
        "\n",
        "# Loading Image path\n",
        "content_images = os.listdir(P365_BASEPATH)\n",
        "content_images = [os.path.join(P365_BASEPATH, path) for path in content_images]\n",
        "\n",
        "style_images = os.listdir(WIKIART_BASEPATH)\n",
        "style_images = [os.path.join(WIKIART_BASEPATH, path) for path in style_images]"
      ],
      "metadata": {
        "id": "5pxoZcrpnf9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing corrupted JPEGs on Unzip process (if any)\n",
        "\n",
        "from struct import unpack\n",
        "\n",
        "marker_mapping = {\n",
        "    0xffd8: \"Start of Image\",\n",
        "    0xffe0: \"Application Default Header\",\n",
        "    0xffdb: \"Quantization Table\",\n",
        "    0xffc0: \"Start of Frame\",\n",
        "    0xffc4: \"Define Huffman Table\",\n",
        "    0xffda: \"Start of Scan\",\n",
        "    0xffd9: \"End of Image\"\n",
        "}\n",
        "\n",
        "class JPEG:\n",
        "\n",
        "    def __init__(self, image_file):\n",
        "        with open(image_file, 'rb') as f:\n",
        "            self.img_data = f.read()\n",
        "    \n",
        "    def decode(self):\n",
        "        data = self.img_data\n",
        "        while(True):\n",
        "            marker, = unpack(\">H\", data[0:2])\n",
        "            if marker == 0xffd8:\n",
        "                data = data[2:]\n",
        "            elif marker == 0xffd9:\n",
        "                return\n",
        "            elif marker == 0xffda:\n",
        "                data = data[-2:]\n",
        "            else:\n",
        "                lenchunk, = unpack(\">H\", data[2:4])\n",
        "                data = data[2+lenchunk:]            \n",
        "            if len(data)==0:\n",
        "                break        \n",
        "\n",
        "\n",
        "corrupted = []\n",
        "\n",
        "for img in tqdm(style_images):\n",
        "  image = JPEG(img) \n",
        "  try:\n",
        "    image.decode()   \n",
        "  except:\n",
        "    corrupted.append(img)\n",
        "\n",
        "for name in corrupted:\n",
        "  style_images.remove(name)"
      ],
      "metadata": {
        "id": "IRJ4jZB8poNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Preprocessing\n",
        "def preprocess_image(image_path, size=IMAGE_SIZE):\n",
        "  \"\"\"\n",
        "    Preprocess the image by decoding and resizing and image \n",
        "    from the image file path.\n",
        "\n",
        "    Args:\n",
        "      image_path: The image file path.\n",
        "      size: The size of the image to be resized to.\n",
        "\n",
        "    Returns:\n",
        "      image: resized image\n",
        "  \"\"\"\n",
        "\n",
        "  image = tf.io.read_file(image_path)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  image = tf.image.convert_image_dtype(image, dtype='float32')\n",
        "  image = tf.image.resize(image, size)\n",
        "\n",
        "  return image\n",
        "\n",
        "# Train Test Splits\n",
        "total_content_images = len(content_images)\n",
        "train_content = content_images[:int(0.8 * total_content_images)]\n",
        "val_content = content_images[int(0.8 * total_content_images):int(0.9 * total_content_images)]\n",
        "test_content = content_images[int(0.9 * total_content_images):]\n",
        "\n",
        "total_style_images = len(style_images)\n",
        "train_style = style_images[:int(0.8 * total_style_images)]\n",
        "val_style = style_images[int(0.8 * total_style_images):int(0.9 * total_style_images)]\n",
        "test_style = style_images[int(0.9 * total_style_images):]\n",
        "\n",
        "# Build the style and content tf.data datasets\n",
        "train_style_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(train_style)\n",
        "    .map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "    .repeat()\n",
        ")\n",
        "\n",
        "val_style_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(val_style)\n",
        "    .map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "    .repeat()\n",
        ")\n",
        "\n",
        "test_style_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(test_style)\n",
        "    .map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "    .repeat()\n",
        ")\n",
        "\n",
        "train_content_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(train_content)\n",
        "    .map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "    .repeat()\n",
        ")\n",
        "\n",
        "val_content_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(val_content)\n",
        "    .map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "    .repeat()\n",
        ")\n",
        "\n",
        "test_content_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(test_content)\n",
        "    .map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "    .repeat()\n",
        ")\n",
        "\n",
        "# Zipping the datasets\n",
        "train_ds = (\n",
        "    tf.data.Dataset.zip((train_style_ds, train_content_ds))\n",
        "    .shuffle(BATCH_SIZE * 2)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n",
        "\n",
        "val_ds = (\n",
        "    tf.data.Dataset.zip((val_style_ds, val_content_ds))\n",
        "    .shuffle(BATCH_SIZE * 2)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n",
        "\n",
        "test_ds = (\n",
        "    tf.data.Dataset.zip((test_style_ds, test_content_ds))\n",
        "    .shuffle(BATCH_SIZE * 2)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "zjrBPRk8vdst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Monitors and Callbacks\n",
        "\n",
        "Creating custom monitors and callbacks to be called on_epoch_end"
      ],
      "metadata": {
        "id": "WgjGOGAxrkA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_style, test_content = next(iter(test_ds))\n",
        "\n",
        "class DisplayMonitor(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    # Encode the style and content image\n",
        "    pass\n",
        "\n",
        "    # Plot the style, content, image\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(20, 5))\n",
        "    ax[0].imshow(tf.keras.preprocessing.image.array_to_img(test_style[0]))\n",
        "    ax[0].set_title(f\"Style: {epoch+1:03d}\")\n",
        "\n",
        "    ax[1].imshow(tf.keras.preprocessing.image.array_to_img(test_content[0]))\n",
        "    ax[1].set_title(f\"Content: {epoch+1:03d}\")\n",
        "\n",
        "    ax[2].imshow(tf.keras.preprocessing.image.array_to_img(test_recon_image[0]))\n",
        "    ax[2].set_title(f\"{MODEL_NAME}: {epoch+1:03d}\")\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "hWPwnRPswK-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir model_checkpoints"
      ],
      "metadata": {
        "id": "S-Tgx-oyw1OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CheckpointMonitor(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    # Saving model checkpoint\n",
        "    if (epoch+1) % CHECKPOINT_PER_EPOCH == 0:\n",
        "      self.model.save_weights(f'model_checkpoints/{MODEL_NAME}_{epoch+1}.ckpt')"
      ],
      "metadata": {
        "id": "ypwubCV0wqG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_logger = keras.callbacks.CSVLogger(f'{MODEL_NAME}_p365-{EPOCHS}-{BATCH_SIZE}.csv', append=True, separator=';')"
      ],
      "metadata": {
        "id": "o4hXhcTDxd8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "  DisplayMonitor(),\n",
        "  CheckpointMonitor(),\n",
        "  csv_logger\n",
        "]"
      ],
      "metadata": {
        "id": "c32pyaRPxJbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Implementation"
      ],
      "metadata": {
        "id": "loWTNuGcxkuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EbVCc7coxnZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result"
      ],
      "metadata": {
        "id": "AoXxvgSjxqq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lxhN7ORzxsIQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}